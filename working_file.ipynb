{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11406410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all okay\n"
     ]
    }
   ],
   "source": [
    "print(\"all okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4210a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398ebec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_TRACING_V2 = os.getenv(\"LANGSMITH_TRACING_V2\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215784b2",
   "metadata": {},
   "source": [
    "Basic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c18a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict,Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05de13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    graph_state:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a8c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state:State) -> State:\n",
    "    print(\"Node 1\")\n",
    "    response=state['graph_state'] + \"I am\"\n",
    "    return {\"graph_state\":response}\n",
    "\n",
    "def node_2(state:State) -> State:\n",
    "    print(\"Node 2\")\n",
    "    response=state['graph_state'] + \" Happy\"\n",
    "    return {\"graph_state\":response}\n",
    "\n",
    "def node_3(state:State) -> State:\n",
    "    print(\"Node 3\")\n",
    "    response=state['graph_state'] + \" sad\"\n",
    "    return {\"graph_state\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa61682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def decision_node(state:State) -> Literal['happy_path','sad_path']:\n",
    "    print(\"Decision Node\")\n",
    "\n",
    "    if random.random() > 0.5:\n",
    "        return 'happy_path'\n",
    "    return 'sad_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff94a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder=StateGraph(State)\n",
    "builder.add_node(\"node_1\",node_1)\n",
    "builder.add_node(\"node_2\",node_2)\n",
    "builder.add_node(\"node_3\",node_3)\n",
    "builder.add_edge(START,\"node_1\")\n",
    "builder.add_node(\"decision_node\",decision_node)\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"node_1\",\n",
    "    decision_node,\n",
    "    {\n",
    "        'happy_path': \"node_2\",\n",
    "        'sad_path': \"node_3\"\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"node_2\",END)\n",
    "builder.add_edge(\"node_3\",END)\n",
    "app=builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3f75c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+          \n",
      "        | __start__ |          \n",
      "        +-----------+          \n",
      "               *               \n",
      "               *               \n",
      "               *               \n",
      "          +--------+           \n",
      "          | node_1 |           \n",
      "          +--------+           \n",
      "          .         .          \n",
      "        ..           ..        \n",
      "       .               .       \n",
      "+--------+          +--------+ \n",
      "| node_2 |          | node_3 | \n",
      "+--------+          +--------+ \n",
      "          *         *          \n",
      "           **     **           \n",
      "             *   *             \n",
      "          +---------+          \n",
      "          | __end__ |          \n",
      "          +---------+          \n"
     ]
    }
   ],
   "source": [
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a24f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\n",
      "Decision Node\n",
      "Node 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is ArunI am sad'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state={\"graph_state\":\"Hi, this is Arun\"}\n",
    "app.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31de417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\n",
      "Decision Node\n",
      "Node 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is ArunI am Happy'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6cd3a",
   "metadata": {},
   "source": [
    "Now we will use agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac52e224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is **New Delhi**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4b57ddf4-d1ae-44da-9829-f367be9356a1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 29, 'total_tokens': 37, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 20}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatGoogleGenerativeAI(model='gemini-2.5-flash',temperature=0)\n",
    "llm.invoke(\"what is the capital of india?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee34b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:int,b:int):\n",
    "    \"\"\"This is the arithimetic function which multiplies two give integers a and b\n",
    "\n",
    "    Args:\n",
    "    a: first int\n",
    "    b: second int\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "tools=[multiply]\n",
    "llm_with_tool=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba3660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "def tool_calling(state:MessagesState):\n",
    "    response=llm_with_tool.invoke(state['messages'])\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d931a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node=ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0828a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_fun(state:MessagesState):\n",
    "    last_message=state[\"messages\"][-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c234db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder1=StateGraph(MessagesState)\n",
    "builder1.add_node(\"llm_with_tools\",tool_calling)\n",
    "builder1.add_node(\"tools\",tool_node)\n",
    "builder1.add_edge(START,\"llm_with_tools\")\n",
    "builder1.add_conditional_edges(\n",
    "    \"llm_with_tools\",\n",
    "    router_fun,\n",
    "    {\n",
    "        \"tool\":\"tools\",\n",
    "        END:END\n",
    "    }\n",
    "\n",
    ")\n",
    "builder1.add_edge(\"tools\",END)\n",
    "app2=builder1.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1359366d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+     \n",
      "        | __start__ |     \n",
      "        +-----------+     \n",
      "              *           \n",
      "              *           \n",
      "              *           \n",
      "      +----------------+  \n",
      "      | llm_with_tools |  \n",
      "      +----------------+  \n",
      "         ..        ..     \n",
      "       ..            .    \n",
      "      .               ..  \n",
      "+-------+               . \n",
      "| tools |             ..  \n",
      "+-------+            .    \n",
      "         **        ..     \n",
      "           **    ..       \n",
      "             *  .         \n",
      "         +---------+      \n",
      "         | __end__ |      \n",
      "         +---------+      \n"
     ]
    }
   ],
   "source": [
    "app2.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea62d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"what is 4 multiplied with 5\"]}\n",
    "state1={\"messages\":[\"how are you\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8cbafb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=app2.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa6e22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 4 multiplied with 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (32faf3b7-21b9-46cc-b440-3af85fdaae12)\n",
      " Call ID: 32faf3b7-21b9-46cc-b440-3af85fdaae12\n",
      "  Args:\n",
      "    b: 5\n",
      "    a: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a273f31",
   "metadata": {},
   "source": [
    "Now we will create REACT structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54bc0f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "how are you\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm doing well, thank you! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response=app2.invoke(state1)\n",
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cc1686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int):\n",
    "    \"\"\"This function adds two intergers a and b.\n",
    "\n",
    "    Args:\n",
    "    a : first integer\n",
    "    b: second integer\n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def divide(a:int,b:int):\n",
    "    \"\"\"This function divides two intergers a and b.\n",
    "\n",
    "    Args:\n",
    "    a : first integer\n",
    "    b: second integer\n",
    "    \"\"\"\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa7425e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_upgrade=[multiply,add,divide]\n",
    "tool_node_upgrade=ToolNode(tool_upgrade)\n",
    "llm_with_tool_upgrade=llm.bind_tools(tool_upgrade)\n",
    "def tool_calling_upgrade(state:MessagesState):\n",
    "    response=llm_with_tool_upgrade.invoke(state['messages'])\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c861ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder2=StateGraph(MessagesState)\n",
    "builder2.add_node(\"llm_with_tool_upgrade\",tool_calling_upgrade)\n",
    "builder2.add_node(\"tools_upgrate\",tool_node_upgrade)\n",
    "builder2.add_edge(START,\"llm_with_tool_upgrade\")\n",
    "builder2.add_conditional_edges(\n",
    "    \"llm_with_tool_upgrade\",\n",
    "    router_fun,\n",
    "    {\n",
    "        \"tool\":\"tools_upgrate\",\n",
    "        END:END\n",
    "    }\n",
    ")\n",
    "builder2.add_edge(\"tools_upgrate\",\"llm_with_tool_upgrade\")\n",
    "\n",
    "app3=builder2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da47b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +-----------+               \n",
      "            | __start__ |               \n",
      "            +-----------+               \n",
      "                  *                     \n",
      "                  *                     \n",
      "                  *                     \n",
      "      +-----------------------+         \n",
      "      | llm_with_tool_upgrade |         \n",
      "      +-----------------------+         \n",
      "           ...         ...              \n",
      "          .               .             \n",
      "        ..                 ..           \n",
      "+---------+           +---------------+ \n",
      "| __end__ |           | tools_upgrate | \n",
      "+---------+           +---------------+ \n"
     ]
    }
   ],
   "source": [
    "app3.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2caf3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state3={\"messages\":[\"Add 3 and 4. Multiply the output by 2. Divide the output by 5\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "085b70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=app3.invoke(state3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03d723e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply the output by 2. Divide the output by 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (fdb41117-d057-462f-8400-65a413d216b3)\n",
      " Call ID: fdb41117-d057-462f-8400-65a413d216b3\n",
      "  Args:\n",
      "    b: 4\n",
      "    a: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (5eadf186-b77a-498c-916b-3cd704496fe8)\n",
      " Call ID: 5eadf186-b77a-498c-916b-3cd704496fe8\n",
      "  Args:\n",
      "    b: 2\n",
      "    a: 7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (0dee0446-a1a3-4ef6-ab0f-5be182e2d1e9)\n",
      " Call ID: 0dee0446-a1a3-4ef6-ab0f-5be182e2d1e9\n",
      "  Args:\n",
      "    b: 5\n",
      "    a: 14\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "2.8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The final answer is 2.8.\n"
     ]
    }
   ],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18f32f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=app3.invoke(state1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ced88050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "how are you\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I am an AI assistant, I do not have personal feelings. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14dfec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
